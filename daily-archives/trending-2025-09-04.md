# Top Python Repo Trending in GitHub — 2025-09-04 (Sorted by Total Stars)

| Rank | Repository | Description | Stars Today | Total Stars | Forks | Built by |
|------|------------|-------------|-------------|-------------|-------|----------|
| 1 | [PaddlePaddle/PaddleOCR](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/dyning/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":null}}' data-hydro-click-hmac="70abde0bab0d89334ffc671a34a50a0bde51fb19cc9dfab7abe8ce3c2f623fe1" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/dyning"><img alt="@dyning" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/10047064?s=40&amp;v=4" width="20"/></a>) | Awesome multilingual OCR and Document Parsing toolkits based on PaddlePaddle (practical ultra lightweight OCR system, support 80+ languages recognition, provide data annotation and synthesis tools, support training and deployment among server, mobile, embedded and IoT devices) | 26 | 53322 | 8575 | [LDOUBLEV](https://github.com/LDOUBLEV), [WenmuZhou](https://github.com/WenmuZhou), [MissPenguin](https://github.com/MissPenguin), [tink2123](https://github.com/tink2123), [dyning](https://github.com/dyning) |
| 2 | [lllyasviel/Fooocus](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/xhoxye/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/xhoxye"><img alt="@xhoxye" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/129571231?s=40&amp;v=4" width="20"/></a>) | Focus on prompting and generating | 24 | 46347 | 7429 | [lllyasviel](https://github.com/lllyasviel), [mashb1t](https://github.com/mashb1t), [MoonRide303](https://github.com/MoonRide303), [xhoxye](https://github.com/xhoxye) |
| 3 | [crewAIInc/crewAI](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/tonykipkemboi/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/tonykipkemboi"><img alt="@tonykipkemboi" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/64493665?s=40&amp;v=4" width="20"/></a>) | Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks. | 804 | 37427 | 4943 | [joaomdmoura](https://github.com/joaomdmoura), [bhancockio](https://github.com/bhancockio), [lorenzejay](https://github.com/lorenzejay), [lucasgomide](https://github.com/lucasgomide), [tonykipkemboi](https://github.com/tonykipkemboi) |
| 4 | [huggingface/diffusers](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/patil-suraj/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending","user_id":9624555}}' data-hydro-click-hmac="ba4cb575a5cafeac3778894c23496f620ed8904c5197b426ac7d8b98cc6e712f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/patil-suraj"><img alt="@patil-suraj" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/27137566?s=40&amp;v=4" width="20"/></a>) | 🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch. | 26 | 30592 | 6285 | [patrickvonplaten](https://github.com/patrickvonplaten), [sayakpaul](https://github.com/sayakpaul), [yiyixuxu](https://github.com/yiyixuxu), [DN6](https://github.com/DN6), [patil-suraj](https://github.com/patil-suraj) |
| 5 | [QwenLM/Qwen3](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/JianxinMa/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":1524716}}' data-hydro-click-hmac="c524f47438bbb13fcd8b9fcb36f7020c3dea180cfec3fe6d428e6cb1b4878f9b" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/JianxinMa"><img alt="@JianxinMa" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/7543016?s=40&amp;v=4" width="20"/></a>) | Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud. | 26 | 24363 | 1686 | [jklj077](https://github.com/jklj077), [JustinLin610](https://github.com/JustinLin610), [bug-orz](https://github.com/bug-orz), [huybery](https://github.com/huybery), [JianxinMa](https://github.com/JianxinMa) |
| 6 | [NVIDIA/Megatron-LM](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/shoeybi/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":null}}' data-hydro-click-hmac="70abde0bab0d89334ffc671a34a50a0bde51fb19cc9dfab7abe8ce3c2f623fe1" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/shoeybi"><img alt="@shoeybi" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/1205686?s=40&amp;v=4" width="20"/></a>) | Ongoing research training transformer models at scale | 21 | 13449 | 3054 | [ko3n1g](https://github.com/ko3n1g), [jaredcasper](https://github.com/jaredcasper), [shanmugamr1992](https://github.com/shanmugamr1992), [lmcafee-nvidia](https://github.com/lmcafee-nvidia), [shoeybi](https://github.com/shoeybi) |
| 7 | [resemble-ai/chatterbox](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/TediPapajorgji/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/TediPapajorgji"><img alt="@TediPapajorgji" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/5790075?s=40&amp;v=4" width="20"/></a>) | SoTA open-source TTS | 283 | 11671 | 1450 | [fatchord](https://github.com/fatchord), [JeremyCCHsu](https://github.com/JeremyCCHsu), [manmay-nakhashi](https://github.com/manmay-nakhashi), [ZohaibAhmed](https://github.com/ZohaibAhmed), [TediPapajorgji](https://github.com/TediPapajorgji) |
| 8 | [oraios/serena](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/dbernazal/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending?since=monthly","user_id":51195595}}' data-hydro-click-hmac="6511edf2d55a3f4dc65c804f8101a1390906f4d7fff36654918c5990f03eb9fe" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/dbernazal"><img alt="@dbernazal" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/2327832?s=40&amp;v=4" width="20"/></a>) | A powerful coding agent toolkit providing semantic retrieval and editing capabilities (MCP server & other integrations) | 229 | 11251 | 792 | [MischaPanch](https://github.com/MischaPanch), [opcode81](https://github.com/opcode81), [mdbenito](https://github.com/mdbenito), [claude](https://github.com/claude), [dbernazal](https://github.com/dbernazal) |
| 9 | [livekit/agents](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/jayeshp19/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/jayeshp19"><img alt="@jayeshp19" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/60539217?s=40&amp;v=4" width="20"/></a>) | A powerful framework for building realtime voice AI agents 🤖🎙️📹 | 16 | 7398 | 1233 | [theomonnom](https://github.com/theomonnom), [longcw](https://github.com/longcw), [keepingitneil](https://github.com/keepingitneil), [davidzhao](https://github.com/davidzhao), [jayeshp19](https://github.com/jayeshp19) |
| 10 | [HKUDS/DeepCode](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/chaohuang-ai/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":1524716}}' data-hydro-click-hmac="c524f47438bbb13fcd8b9fcb36f7020c3dea180cfec3fe6d428e6cb1b4878f9b" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/chaohuang-ai"><img alt="@chaohuang-ai" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/204865953?s=40&amp;v=4" width="20"/></a>) | "DeepCode: Open Agentic Coding (Paper2Code & Text2Web & Text2Backend)" | 160 | 5408 | 665 | [Zongwei9888](https://github.com/Zongwei9888), [LarFii](https://github.com/LarFii), [LZH-YS1998](https://github.com/LZH-YS1998), [chaohuang-ai](https://github.com/chaohuang-ai) |
| 11 | [lfnovo/open-notebook](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/cubxxw/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":1524716}}' data-hydro-click-hmac="c524f47438bbb13fcd8b9fcb36f7020c3dea180cfec3fe6d428e6cb1b4878f9b" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/cubxxw"><img alt="@cubxxw" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/86140903?s=40&amp;v=4" width="20"/></a>) | An Open Source implementation of Notebook LM with more flexibility and features | 32 | 4044 | 416 | [lfnovo](https://github.com/lfnovo), [pchuri](https://github.com/pchuri), [cubxxw](https://github.com/cubxxw) |
| 12 | [JefferyHcool/BiliNote](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/claude/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python","user_id":86586602}}' data-hydro-click-hmac="f77a4b6d04f1dcb1e27efe50dd0f028f55b635dd3b7e340d9580fca25027146c" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/claude"><img alt="@claude" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/81847?s=40&amp;v=4" width="20"/></a>) | AI 视频笔记生成工具 让 AI 为你的视频做笔记 | 30 | 3482 | 392 | [JefferyHcool](https://github.com/JefferyHcool), [Karasukaigan](https://github.com/Karasukaigan), [SurfRid3r](https://github.com/SurfRid3r), [Paper-Dragon](https://github.com/Paper-Dragon), [claude](https://github.com/claude) |
| 13 | [denizsafak/abogen](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/KyleAure/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/KyleAure"><img alt="@KyleAure" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/33664635?s=40&amp;v=4" width="20"/></a>) | Generate audiobooks from EPUBs, PDFs and text with synchronized captions. | 36 | 3447 | 176 | [denizsafak](https://github.com/denizsafak), [jborza](https://github.com/jborza), [robmckinnon](https://github.com/robmckinnon), [KyleAure](https://github.com/KyleAure) |
| 14 | [murtaza-nasir/maestro](<a class="d-inline-block" data-hovercard-type="user" data-hovercard-url="/users/nrynss/hovercard" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/nrynss"><img alt="@nrynss" class="avatar mb-1 avatar-user" height="20" src="https://avatars.githubusercontent.com/u/9533376?s=40&amp;v=4" width="20"/></a>) | MAESTRO is an AI-powered research application designed to streamline complex research tasks. | 68 | 1145 | 99 | [murtaza-nasir](https://github.com/murtaza-nasir), [claude](https://github.com/claude), [mlaug](https://github.com/mlaug), [nrynss](https://github.com/nrynss) |
| 15 | [microsoft/rStar](<a class="d-inline-block" data-hydro-click='{"event_type":"explore.click","payload":{"click_context":"TRENDING_REPOSITORIES_PAGE","click_target":"CONTRIBUTING_DEVELOPER","click_visual_representation":"DEVELOPER_AVATAR","actor_id":null,"record_id":null,"originating_url":"https://github.com/trending/python?since=daily","user_id":59230387}}' data-hydro-click-hmac="312ff21d0970a6bad5d6efe56908304dda3718cd130ab46b1e73020517553c5f" href="/apps/microsoft-github-operations"><img alt="@microsoft-github-operations" class="avatar mb-1" height="20" src="https://avatars.githubusercontent.com/in/41902?s=40&amp;v=4" width="20"/></a>) | No description | 48 | 961 | 87 | [microsoftopensource](https://github.com/microsoftopensource), [J-shang](https://github.com/J-shang) |
